/**
 * Embedding Generator Module
 * Gera embeddings vetoriais usando OpenAI text-embedding-3-small
 * Suporta batch processing e retry logic
 */

import OpenAI from 'openai';

// Inicializa cliente OpenAI (lazy initialization para evitar erro se API key n√£o estiver configurada)
let openai = null;

function getOpenAIClient() {
  if (!openai) {
    if (!process.env.OPENAI_API_KEY) {
      throw new Error('OPENAI_API_KEY n√£o configurada no ambiente');
    }
    openai = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY
    });
  }
  return openai;
}

/**
 * Modelo de embedding padr√£o
 * text-embedding-3-small: 1536 dimens√µes, $0.00002/1K tokens
 * Melhor custo-benef√≠cio para a maioria dos casos
 */
const DEFAULT_MODEL = 'text-embedding-3-small';
const DEFAULT_DIMENSIONS = 1536;

/**
 * Gera embedding para um √∫nico texto
 * 
 * @param {string} text - Texto a ser embedado
 * @param {Object} options - Configura√ß√µes
 * @returns {Promise<{embedding: Array<number>, tokens: number, model: string}>}
 */
export async function generateEmbedding(text, options = {}) {
  const {
    model = DEFAULT_MODEL,
    dimensions = DEFAULT_DIMENSIONS,
    maxRetries = 3,
    retryDelay = 1000
  } = options;

  if (!text || text.trim().length === 0) {
    throw new Error('Texto vazio n√£o pode ser embedado');
  }

  if (!process.env.OPENAI_API_KEY) {
    throw new Error('OPENAI_API_KEY n√£o configurada no ambiente');
  }

  let lastError;
  
  for (let attempt = 0; attempt < maxRetries; attempt++) {
    try {
      const client = getOpenAIClient();
      const response = await client.embeddings.create({
        model,
        input: text,
        dimensions
      });

      return {
        embedding: response.data[0].embedding,
        tokens: response.usage.total_tokens,
        model: response.model,
        dimensions: response.data[0].embedding.length
      };

    } catch (error) {
      lastError = error;
      
      // Rate limit ou erro tempor√°rio: aguarda e tenta novamente
      if (attempt < maxRetries - 1) {
        const delay = retryDelay * Math.pow(2, attempt); // Exponential backoff
        console.warn(`‚ö†Ô∏è Erro ao gerar embedding (tentativa ${attempt + 1}/${maxRetries}): ${error.message}`);
        console.warn(`   Aguardando ${delay}ms antes de tentar novamente...`);
        await new Promise(resolve => setTimeout(resolve, delay));
      }
    }
  }

  throw new Error(`Falha ao gerar embedding ap√≥s ${maxRetries} tentativas: ${lastError.message}`);
}

/**
 * Gera embeddings em lote (batch)
 * OpenAI suporta at√© 2048 inputs por request
 * 
 * @param {Array<string>} texts - Array de textos
 * @param {Object} options - Configura√ß√µes
 * @returns {Promise<Array<{embedding: Array<number>, index: number, tokens: number}>>}
 */
export async function generateEmbeddingsBatch(texts, options = {}) {
  const {
    model = DEFAULT_MODEL,
    dimensions = DEFAULT_DIMENSIONS,
    batchSize = 100, // OpenAI recomenda lotes menores para estabilidade
    maxRetries = 3,
    retryDelay = 1000,
    onProgress = null // Callback: (current, total) => {}
  } = options;

  if (!texts || texts.length === 0) {
    return [];
  }

  if (!process.env.OPENAI_API_KEY) {
    throw new Error('OPENAI_API_KEY n√£o configurada no ambiente');
  }

  const results = [];
  const totalBatches = Math.ceil(texts.length / batchSize);

  for (let i = 0; i < texts.length; i += batchSize) {
    const batch = texts.slice(i, i + batchSize);
    const batchNumber = Math.floor(i / batchSize) + 1;

    console.log(`üì¶ Processando lote ${batchNumber}/${totalBatches} (${batch.length} textos)...`);

    let lastError;
    let batchResults = null;

    for (let attempt = 0; attempt < maxRetries; attempt++) {
      try {
        const client = getOpenAIClient();
        const response = await client.embeddings.create({
          model,
          input: batch,
          dimensions
        });

        batchResults = response.data.map((item, idx) => ({
          embedding: item.embedding,
          index: i + idx,
          tokens: Math.ceil(response.usage.total_tokens / batch.length), // Aproxima√ß√£o
          dimensions: item.embedding.length
        }));

        break; // Sucesso, sai do loop de retry

      } catch (error) {
        lastError = error;

        if (attempt < maxRetries - 1) {
          const delay = retryDelay * Math.pow(2, attempt);
          console.warn(`‚ö†Ô∏è Erro no lote ${batchNumber} (tentativa ${attempt + 1}/${maxRetries}): ${error.message}`);
          console.warn(`   Aguardando ${delay}ms antes de tentar novamente...`);
          await new Promise(resolve => setTimeout(resolve, delay));
        }
      }
    }

    if (!batchResults) {
      throw new Error(`Falha no lote ${batchNumber} ap√≥s ${maxRetries} tentativas: ${lastError.message}`);
    }

    results.push(...batchResults);

    // Callback de progresso
    if (onProgress) {
      onProgress(results.length, texts.length);
    }

    // Delay entre lotes para evitar rate limits (ajust√°vel)
    if (i + batchSize < texts.length) {
      await new Promise(resolve => setTimeout(resolve, 500));
    }
  }

  return results;
}

/**
 * Calcula similaridade cosseno entre dois vetores
 * √ötil para validar embeddings localmente
 * 
 * @param {Array<number>} vecA - Primeiro vetor
 * @param {Array<number>} vecB - Segundo vetor
 * @returns {number} - Similaridade entre -1 e 1 (1 = id√™nticos)
 */
export function cosineSimilarity(vecA, vecB) {
  if (!vecA || !vecB || vecA.length !== vecB.length) {
    throw new Error('Vetores inv√°lidos ou dimens√µes incompat√≠veis');
  }

  let dotProduct = 0;
  let normA = 0;
  let normB = 0;

  for (let i = 0; i < vecA.length; i++) {
    dotProduct += vecA[i] * vecB[i];
    normA += vecA[i] * vecA[i];
    normB += vecB[i] * vecB[i];
  }

  return dotProduct / (Math.sqrt(normA) * Math.sqrt(normB));
}

/**
 * Valida se um embedding est√° no formato correto
 * 
 * @param {Array<number>} embedding - Vetor a validar
 * @param {number} expectedDimensions - Dimens√µes esperadas (default: 1536)
 * @returns {Object} - {valid: boolean, error: string}
 */
export function validateEmbedding(embedding, expectedDimensions = DEFAULT_DIMENSIONS) {
  if (!Array.isArray(embedding)) {
    return { valid: false, error: 'Embedding n√£o √© um array' };
  }

  if (embedding.length !== expectedDimensions) {
    return { 
      valid: false, 
      error: `Embedding tem ${embedding.length} dimens√µes (esperado: ${expectedDimensions})` 
    };
  }

  if (embedding.some(val => typeof val !== 'number' || isNaN(val))) {
    return { valid: false, error: 'Embedding cont√©m valores n√£o-num√©ricos' };
  }

  // Verifica se o vetor est√° normalizado (norma pr√≥xima de 1)
  const norm = Math.sqrt(embedding.reduce((sum, val) => sum + val * val, 0));
  if (Math.abs(norm - 1.0) > 0.01) {
    return { 
      valid: false, 
      error: `Embedding n√£o est√° normalizado (norma: ${norm.toFixed(4)})` 
    };
  }

  return { valid: true };
}

/**
 * Estima custo de embeddings
 * text-embedding-3-small: $0.00002/1K tokens
 * 
 * @param {number} totalTokens - Total de tokens processados
 * @param {string} model - Modelo usado
 * @returns {Object} - {cost: number, costFormatted: string}
 */
export function estimateCost(totalTokens, model = DEFAULT_MODEL) {
  const costs = {
    'text-embedding-3-small': 0.00002, // $0.02 per 1M tokens
    'text-embedding-3-large': 0.00013, // $0.13 per 1M tokens
    'text-embedding-ada-002': 0.0001   // $0.10 per 1M tokens (legacy)
  };

  const pricePerToken = costs[model] || costs['text-embedding-3-small'];
  const cost = (totalTokens / 1000) * pricePerToken;

  return {
    cost,
    costFormatted: `$${cost.toFixed(4)}`,
    tokens: totalTokens,
    model
  };
}

export default {
  generateEmbedding,
  generateEmbeddingsBatch,
  cosineSimilarity,
  validateEmbedding,
  estimateCost,
  DEFAULT_MODEL,
  DEFAULT_DIMENSIONS
};
