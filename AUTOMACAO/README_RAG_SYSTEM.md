# Sistema RAG (Retrieval-Augmented Generation) - Documenta√ß√£o Completa

## üéØ Vis√£o Geral

Sistema completo de RAG implementado no VCM para permitir que personas respondam perguntas baseadas em conhecimento espec√≠fico armazenado em base vetorial.

## üì¶ Componentes Implementados

### 1. **Infraestrutura de Dados**

#### `src/sql/create_knowledge_chunks_table.sql`
Tabela PostgreSQL com suporte pgvector:
- Campos: id, persona_id, topic, content, embedding (1536d), source, chunk_index, metadata
- √çndice HNSW para busca vetorial otimizada (cosine similarity)
- View `knowledge_stats_by_persona` para estat√≠sticas agregadas

#### `src/sql/create_match_function.sql`
Fun√ß√£o PL/pgSQL para busca vetorial:
```sql
match_knowledge_chunks(
  query_embedding VECTOR(1536),
  match_threshold FLOAT DEFAULT 0.7,
  match_count INT DEFAULT 5,
  filter_persona_id UUID DEFAULT NULL
)
```
Retorna chunks ordenados por similaridade cosseno.

---

### 2. **Processamento de Documentos**

#### `AUTOMACAO/lib/text-chunker.js`
M√≥dulo de divis√£o de texto em chunks otimizados:
- **3 estrat√©gias**: fixed-size, semantic, hybrid (recomendada)
- **Overlap configur√°vel**: mant√©m contexto entre chunks
- **Valida√ß√£o**: tamanho, tokens, limites do modelo (8191 tokens)

Fun√ß√µes principais:
```javascript
chunkByFixedSize(text, chunkSize=1000, overlap=200)
chunkBySemantic(text, minSize=500, maxSize=1500)
chunkHybrid(text, options) // Recomendada
validateChunks(chunks, maxTokens=8000)
estimateTokens(text)
```

#### `AUTOMACAO/lib/embedding-generator.js`
Gera√ß√£o de embeddings com OpenAI:
- **Modelo**: text-embedding-3-small (1536 dimens√µes)
- **Custo**: $0.00002 por 1K tokens (~100x mais barato que GPT-4o)
- **Batch processing**: at√© 100 textos por request
- **Retry logic**: exponential backoff para rate limits

Fun√ß√µes principais:
```javascript
generateEmbedding(text, options)
generateEmbeddingsBatch(texts, options)
validateEmbedding(embedding, expectedDimensions)
estimateCost(totalTokens, model)
cosineSimilarity(vecA, vecB)
```

#### `AUTOMACAO/10_generate_knowledge_base.js`
Script principal de ingest√£o:
```bash
node 10_generate_knowledge_base.js \
  --empresaId=UUID \
  --source=caminho/arquivo.txt
```

Fluxo:
1. Carrega documentos (TXT, MD)
2. Divide em chunks (hybrid chunking)
3. Gera embeddings (OpenAI)
4. Match personas relevantes (baseado em Script 6.5)
5. Salva chunks + embeddings no banco

---

### 3. **Retrieval (Busca Vetorial)**

#### `AUTOMACAO/lib/rag-retriever.js`
Sistema de recupera√ß√£o de conhecimento:

**Busca vetorial b√°sica:**
```javascript
retrieveRelevantChunks(query, personaId, options={
  topK: 5,
  minSimilarity: 0.7,
  includeMetadata: true
})
```

**Busca h√≠brida (vector + keywords):**
```javascript
hybridSearch(query, keywords=[], personaId, options)
```

**Formata√ß√£o de contexto:**
```javascript
formatChunksAsContext(chunks, maxTokens=3000)
```

**Sugest√µes de perguntas:**
```javascript
suggestRelatedQuestions(chunks)
```

---

### 4. **APIs e Endpoints**

#### `src/app/api/knowledge/upload/route.ts`
Upload de documentos:

**POST /api/knowledge/upload**
```json
{
  "file": File,
  "empresaId": "uuid",
  "topic": "opcional"
}
```

Valida√ß√µes:
- Extens√µes: .txt, .md, .pdf, .docx
- Tamanho m√°ximo: 10MB
- Organiza√ß√£o por empresa em diret√≥rios

#### `src/app/api/rag/query/route.ts`
Consulta RAG com LLM:

**POST /api/rag/query**
```json
{
  "query": "Como melhorar vendas?",
  "personaId": "uuid",
  "topK": 5,
  "minSimilarity": 0.7,
  "useHybrid": false,
  "keywords": []
}
```

**Resposta:**
```json
{
  "success": true,
  "answer": "Resposta gerada pelo LLM...",
  "chunks": [
    {
      "topic": "CRM Best Practices",
      "source": "sales_guide.txt",
      "similarity": 0.89,
      "preview": "..."
    }
  ],
  "stats": {
    "retrievalTime": 145,
    "generationTime": 1234,
    "chunksFound": 5,
    "tokensUsed": 856
  },
  "suggestedQuestions": [...]
}
```

Fluxo interno:
1. Gera embedding da query
2. Busca chunks relevantes (cosine similarity)
3. Formata contexto (max 3000 tokens)
4. Envia para GPT-4o com system prompt espec√≠fico
5. Retorna resposta + metadados

---

### 5. **Testing & Validation**

#### `AUTOMACAO/11_test_rag_system.js`
Script de testes automatizados:

```bash
node 11_test_rag_system.js --empresaId=UUID [--personaId=UUID]
```

Executa 5 perguntas padr√£o para cada persona:
1. "Quais s√£o minhas principais responsabilidades?"
2. "Que ferramentas devo usar no meu trabalho?"
3. "Como posso melhorar meu desempenho?"
4. "Quais s√£o as melhores pr√°ticas da minha √°rea?"
5. "Que KPIs devo acompanhar?"

**Relat√≥rio gerado:**
```json
{
  "summary": {
    "totalPersonas": 16,
    "totalTests": 80,
    "successfulTests": 76,
    "successRate": "95.0%"
  },
  "performance": {
    "avgRetrievalTime": "142ms",
    "avgGenerationTime": "1523ms",
    "avgTotalTime": "1665ms"
  },
  "quality": {
    "high": 62,
    "medium": 12,
    "low": 2
  }
}
```

M√©tricas de qualidade:
- **Alta**: similarity > 0.8 + resposta espec√≠fica
- **M√©dia**: similarity > 0.6 + resposta gen√©rica
- **Baixa**: similarity < 0.6 ou resposta vaga

---

### 6. **Interface de Usu√°rio**

#### `src/components/PersonaChat.tsx`
Componente React de chat interativo:

**Features:**
- Interface de mensagens estilo chat
- Exibi√ß√£o de fontes utilizadas (chunks)
- M√©tricas de performance (tempo, sources)
- Sugest√µes de perguntas relacionadas
- Loading states e error handling
- Auto-scroll para √∫ltima mensagem

**Props:**
```typescript
interface PersonaChatProps {
  personaId: string;
  personaName: string;
  personaCargo: string;
  empresaId?: string;
}
```

**Uso:**
```tsx
<PersonaChat
  personaId="123e4567..."
  personaName="Maria Silva"
  personaCargo="Sales Manager"
  empresaId="456e7890..."
/>
```

---

## üöÄ Fluxo de Uso Completo

### Setup Inicial (executar uma vez)

```bash
# 1. Criar tabelas no Supabase
psql -h db.fzyokrvdyeczhfqlwxzb.supabase.co -U postgres -d postgres \
  -f src/sql/create_knowledge_chunks_table.sql \
  -f src/sql/create_match_function.sql

# 2. Verificar extens√£o pgvector
psql> SELECT * FROM pg_extension WHERE extname = 'vector';
```

### Ingest√£o de Conhecimento

```bash
# 1. Preparar documentos
mkdir -p AUTOMACAO/knowledge_uploads
echo "Sales best practices..." > AUTOMACAO/knowledge_uploads/sales_guide.txt

# 2. Processar documentos
cd AUTOMACAO
node 10_generate_knowledge_base.js \
  --empresaId=27470d32-9cce-4975-9a62-1d76f3ab77a4 \
  --source=knowledge_uploads/sales_guide.txt

# 3. Verificar chunks no banco
psql> SELECT COUNT(*) FROM knowledge_chunks;
psql> SELECT * FROM knowledge_stats_by_persona;
```

### Testes de Qualidade

```bash
# Testar sistema RAG
node 11_test_rag_system.js \
  --empresaId=27470d32-9cce-4975-9a62-1d76f3ab77a4

# Relat√≥rio gerado em: rag_test_output/rag_test_report_YYYY-MM-DD.json
```

### Integra√ß√£o na UI

```typescript
// P√°gina de detalhes da persona
import { PersonaChat } from '@/components/PersonaChat';

export default function PersonaDetailPage({ params }) {
  return (
    <div className="grid grid-cols-2 gap-4">
      <div>
        {/* Informa√ß√µes da persona */}
      </div>
      <div>
        <PersonaChat
          personaId={params.id}
          personaName={persona.nome}
          personaCargo={persona.cargo}
        />
      </div>
    </div>
  );
}
```

### Consultas via API

```javascript
// Exemplo de fetch
const response = await fetch('/api/rag/query', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    query: 'Como melhorar vendas de CRM?',
    personaId: '123e4567-e89b-12d3-a456-426614174000',
    topK: 5,
    minSimilarity: 0.7
  })
});

const data = await response.json();
console.log(data.answer);
console.log(data.chunks); // Fontes utilizadas
console.log(data.stats);  // Performance metrics
```

---

## üìä M√©tricas e Performance

### Custos Estimados

**Embeddings (Script 10):**
- Modelo: text-embedding-3-small
- Pre√ßo: $0.00002 / 1K tokens
- Exemplo: 1000 p√°ginas (~500K tokens) = $0.01

**Gera√ß√£o de Respostas (API /rag/query):**
- Modelo: GPT-4o
- Pre√ßo: $0.0025 / 1K input tokens, $0.01 / 1K output tokens
- Exemplo por query: ~$0.005 (contexto 3K tokens + resposta 500 tokens)

**Compara√ß√£o:**
- Embeddings: ~100x mais baratos que LLM
- RAG vs. Fine-tuning: RAG = $0.01/1000 docs, Fine-tuning = $3.00

### Performance T√≠pica

**Retrieval (busca vetorial):**
- Top-5 chunks: 100-200ms
- Top-10 chunks: 150-300ms
- Depende de: tamanho da base, √≠ndice HNSW

**Generation (LLM):**
- GPT-4o: 1-2 segundos (500 tokens output)
- GPT-4o-mini: 0.5-1 segundo (mais r√°pido, menos preciso)

**Total por query:**
- M√©dia: 1.5-2.5 segundos
- Com cache de embeddings: <1 segundo

### Escalabilidade

**Banco de dados:**
- pgvector suporta milh√µes de vetores
- √çndice HNSW: O(log N) busca
- Recomendado: sharding por empresa_id acima de 1M chunks

**Rate Limits OpenAI:**
- Embeddings: 3000 requests/min (tier 1)
- GPT-4o: 500 requests/min (tier 1)
- Solu√ß√£o: queue system para batch processing

---

## üîß Troubleshooting

### Erro: "pgvector extension not found"

```sql
-- Habilitar no Supabase Dashboard ‚Üí SQL Editor
CREATE EXTENSION IF NOT EXISTS vector;
```

### Erro: "Could not find the column 'embedding'"

Tabela `knowledge_chunks` n√£o existe. Execute:
```bash
psql -f src/sql/create_knowledge_chunks_table.sql
```

### Similarity scores muito baixos (<0.5)

Poss√≠veis causas:
1. **Documentos irrelevantes**: conhecimento n√£o relacionado √† persona
2. **Chunking inadequado**: chunks muito pequenos/grandes
3. **Query amb√≠gua**: reformular pergunta

Solu√ß√£o:
```javascript
// Reduzir threshold
{ minSimilarity: 0.5 }

// Usar busca h√≠brida
{ useHybrid: true, keywords: ['CRM', 'vendas'] }
```

### Timeout em queries

Causas:
1. Embedding da query demora
2. Busca vetorial lenta (banco sem √≠ndice)
3. LLM gerando resposta longa

Solu√ß√£o:
```javascript
// Reduzir topK
{ topK: 3 }

// Reduzir max_tokens do LLM
{ max_tokens: 300 }

// Verificar √≠ndice HNSW
psql> \d knowledge_chunks
```

---

## üéØ Pr√≥ximos Passos

### Melhorias Poss√≠veis

1. **Re-ranking**: cross-encoder para melhorar ordem dos resultados
2. **Cache de embeddings**: Redis para queries frequentes
3. **Feedback loop**: usu√°rio avalia resposta ‚Üí treina modelo
4. **Multi-modal**: suporte para imagens e PDFs
5. **Streaming**: resposta em tempo real (SSE)
6. **Analytics**: dashboard de m√©tricas de uso e qualidade

### Expans√£o de Features

1. **Context window din√¢mico**: ajusta max tokens baseado na query
2. **Conversational memory**: mant√©m hist√≥rico de mensagens
3. **Multi-persona chat**: grupo de personas colaborando
4. **Knowledge graph**: rela√ß√µes entre chunks
5. **Auto-update**: re-embedding autom√°tico de documentos editados

---

## üìö Refer√™ncias

- [OpenAI Embeddings Guide](https://platform.openai.com/docs/guides/embeddings)
- [pgvector Documentation](https://github.com/pgvector/pgvector)
- [Supabase Vector Guide](https://supabase.com/docs/guides/ai/vector-columns)
- [RAG Best Practices (Pinecone)](https://www.pinecone.io/learn/retrieval-augmented-generation/)
- [HNSW Algorithm Paper](https://arxiv.org/abs/1603.09320)

---

**Status:** ‚úÖ Sistema RAG 100% funcional e pronto para produ√ß√£o
